# web-scraper

This web scraper is an automated tool designed to extract data from websites. It navigates web pages, retrieves relevant content, and processes the extracted information for various uses, such as data analysis, research, and business insights.
In this project, the web scraper:


✅ Fetches web pages using Selenium, simulating a browser.
✅ Extracts relevant content (like text, links, or tables) using BeautifulSoup.
✅ Cleans and processes data for better readability. 
✅Uses ollam’s Llama 3.1 for getting info easily.
✅ Displays results in a user-friendly Streamlit web app where users can enter a URL, scrape content, and view stored data.
Steps to Execute the Scraper Project

Install Required Software
•	Install Python
•	Install Google Chrome and ChromeDriver- https://developer.chrome.com/docs/chromedriver/downloads [make sure the chrome version and chromedriver version are the same ]
Install Required Python Libraries
•	Open Command Prompt and run: 
•	pip install requirements.txt
Run the Web Scraper
•	Install all the python dependencies.
•	Make sure script.py, scrape.py, main.py and the chromedriver are in the same folder.
Start the Streamlit Web App
•	In the terminal of vscode, run: 
•	streamlit run main.py
•	This opens a web interface where you can enter a URL, scrape it, and view it.
